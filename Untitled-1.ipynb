{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import torch \n",
    "from sklearn.datasets import fetch_20newsgroups \n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "#import spacy\n",
    "import ast \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: requests in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joshu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "decoding with 'zlib_codec' codec failed (KeyboardInterrupt: )",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Joshu\\AppData\\Local\\Programs\\Python\\Python38\\lib\\encodings\\zlib_codec.py:19\u001b[0m, in \u001b[0;36mzlib_decode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39massert\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mreturn\u001b[39;00m (zlib\u001b[39m.\u001b[39;49mdecompress(\u001b[39minput\u001b[39;49m), \u001b[39mlen\u001b[39m(\u001b[39minput\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Joshu\\Downloads\\Final Project Lign 167\\Untitled-1.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Joshu/Downloads/Final%20Project%20Lign%20167/Untitled-1.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m twenty_news_train\u001b[39m=\u001b[39m fetch_20newsgroups(remove\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mheaders\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mfooters\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Joshu/Downloads/Final%20Project%20Lign%20167/Untitled-1.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m twenty_news_test\u001b[39m=\u001b[39m fetch_20newsgroups(subset\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m,remove\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mfooters\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Joshu\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py:258\u001b[0m, in \u001b[0;36mfetch_20newsgroups\u001b[1;34m(data_home, subset, categories, shuffle, random_state, remove, download_if_missing, return_X_y)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(cache_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    257\u001b[0m         compressed_content \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 258\u001b[0m     uncompressed_content \u001b[39m=\u001b[39m codecs\u001b[39m.\u001b[39;49mdecode(compressed_content, \u001b[39m\"\u001b[39;49m\u001b[39mzlib_codec\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    259\u001b[0m     cache \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mloads(uncompressed_content)\n\u001b[0;32m    260\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: decoding with 'zlib_codec' codec failed (KeyboardInterrupt: )"
     ]
    }
   ],
   "source": [
    "twenty_news_train= fetch_20newsgroups(remove=(\"headers\",\"footers\"))\n",
    "twenty_news_test= fetch_20newsgroups(subset=\"test\",remove=(\"headers\",\"footers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 0 Data Exploration\n",
    "print(twenty_news_train.DESCR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(twenty_news_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the Classes, we Roughly have a few main \"Categories\" The articles Cover, with numerous subtopics, (that are a large part but not completely encompassing the main categories)\n",
    "1. Science \n",
    "2. Religion \n",
    "3. Politics \n",
    "4. Recreation/Sports\n",
    "5. Technology/Computers\n",
    "\n",
    "In an ideal world, we would see the model. be able to seperate all these labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twenty_news_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_229351/455299691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 1 Setting up Data Frames and Tokenizing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbase_data_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwenty_news_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbase_data_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwenty_news_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'twenty_news_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 1 Setting up Data Frames and Tokenizing \n",
    "base_data_train=twenty_news_train.data\n",
    "base_data_test=twenty_news_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the data\n",
    "\n",
    "\n",
    "#Converting the Various Corpus to a list of sentences\n",
    "def article_to_sents(article):\n",
    "    nlp = spacy.load('en_core_web_sm') \n",
    "    sentences = [i.text for i in nlp(article).sents]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "\n",
    "#Takes a list of sentences and creates a list of the tokenized sentences \n",
    "#https://towardsdatascience.com/how-to-use-bert-from-the-hugging-face-transformer-library-d373a22b0209\n",
    "\n",
    "\n",
    "def sents_to_tokenized_list(marked_sents): \n",
    "    tokenizer= BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "    tokenized_list=[]\n",
    "    maskingattention=[]\n",
    "\n",
    "    #Normally, for Bert, We would tokenize it first and then take the tokenized response and encode it with the id's from the library in two seperate parts \n",
    "    #However, with encode_plus, both are done at once. Add Special tokens add the specific tokens needed that the bert model is trained for.\n",
    "    for sents in marked_sents: \n",
    "        tokens=tokenizer.encode_plus(sents, add_special_tokens = True,truncation = True,  max_length = 52, padding='max_length',return_attention_mask = True, return_tensors = \"pt\")\n",
    "        tokenized_list.append(tokens[\"input_ids\"])\n",
    "        maskingattention.append(tokens['attention_mask'])\n",
    "\n",
    "    return tokenized_list,maskingattention,\n",
    "\n",
    "\n",
    "\n",
    "def create_dataframe(base_data): \n",
    "\n",
    "    df= pd.DataFrame(base_data,columns=[\"Articles\"])\n",
    "    sentences=[] \n",
    "    tokens=[] \n",
    "    masking=[]\n",
    "  \n",
    "    for a in range(df.shape[0]):\n",
    "        article= df.iloc[a].values[0]\n",
    "        sents=article_to_sents(article)\n",
    "        sentences.append(sents)\n",
    "        tokenized_list, mask=sents_to_tokenized_list(sents)\n",
    "        tokens.append(tokenized_list) \n",
    "        masking.append(mask)\n",
    "      \n",
    "      \n",
    "    df[\"Sentences\"]=sentences \n",
    "    df[\"Tokens\"]=tokens \n",
    "    df[\"Attention_Masking\"]=masking\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Joshu\\Downloads\\Final Project Lign 167\\Untitled-1.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Joshu/Downloads/Final%20Project%20Lign%20167/Untitled-1.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m=\u001b[39mcreate_dataframe(base_data_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "df=create_dataframe(base_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#due to the incredible length it takes to run a portion of code and dataframe's do not like tensors (as it saves it as strings, tocsv_converter and csv_converter aim to help save at least the raw data beore embeddings)\n",
    "def tocsv_converter(df):\n",
    "    \n",
    "    df=df[[\"Tokens\",\"Attention_Masking\"]]\n",
    "    temp_tokens=[] \n",
    "    temp_masking=[]\n",
    "\n",
    "    for a in range(df[\"Tokens\"].shape[0]): \n",
    "       \n",
    "        token=df[\"Tokens\"][a]\n",
    "        mask=df[\"Attention_Masking\"][a]\n",
    "        individual_token=[]\n",
    "        individual_mask=[]\n",
    "        \n",
    "        for b in range(len(token)): \n",
    "            \n",
    "            individual_token.append(token[b].tolist()) \n",
    "            individual_mask.append(mask[b].tolist())\n",
    "            \n",
    "        temp_tokens.append(individual_token)\n",
    "        temp_masking.append(individual_mask) \n",
    "\n",
    "    df[\"Tokens\"]=temp_tokens \n",
    "    df[\"Attention_Masking\"]=temp_masking\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_converter(df):\n",
    "\n",
    "\n",
    "    temp_tokens=[] \n",
    "    temp_masking=[]\n",
    "    df=df[[\"Tokens\",\"Attention_Masking\"]] \n",
    "    for a in range(len(df)): \n",
    "        token=ast.literal_eval(df[\"Tokens\"][a])\n",
    "        mask=ast.literal_eval(df[\"Attention_Masking\"][a])\n",
    "        individual_token=[]\n",
    "        individual_mask=[]\n",
    "        for b in range(len(token)): \n",
    "           individual_token.append(torch.tensor((token[b])))\n",
    "           individual_mask.append(torch.tensor((mask[b])))\n",
    "        temp_tokens.append(individual_token)\n",
    "        temp_masking.append(individual_mask)  \n",
    "\n",
    "    \n",
    "    df[\"Tokens\"]=temp_tokens \n",
    "    df[\"Attention_Masking\"]=temp_masking\n",
    "    return(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshu\\AppData\\Local\\Temp\\ipykernel_7120\\2602210127.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Tokens\"]=temp_tokens\n",
      "C:\\Users\\Joshu\\AppData\\Local\\Temp\\ipykernel_7120\\2602210127.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Attention_Masking\"]=temp_masking\n"
     ]
    }
   ],
   "source": [
    "#grabbing the results of the pre-proccesssing before the embeddings\n",
    "df1=pd.read_csv(\"df.csv\")\n",
    "df1=csv_converter(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Creating Embeddings \n",
    "#https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/ \n",
    "\n",
    "\n",
    "def create_embeddings_1_sentence(df):\n",
    "    \n",
    "    model= BertModel.from_pretrained('bert-base-cased', output_hidden_states = True) \n",
    "    model.eval() \n",
    "    num=(df[\"Tokens\"][0][0]).size(1) \n",
    "    \n",
    "    final_outputs=[]\n",
    "    for a in range(df.shape[0]):\n",
    "\n",
    "        tokens_list=df['Tokens'][a]\n",
    "        masking_list=df[\"Attention_Masking\"][a]\n",
    "        outputs_list=[]\n",
    "\n",
    "        for b in range(len(tokens_list)):\n",
    "            token=tokens_list[b]\n",
    "            masking=masking_list[b]\n",
    "            type(masking)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(token,attention_mask=masking) \n",
    "            outputs_list.append(outputs)\n",
    "        final_outputs.append(outputs_list) \n",
    "   \n",
    "    df[\"output_1_sentence\"]=final_outputs\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\Joshu\\AppData\\Local\\Temp\\ipykernel_7120\\4040031756.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"output_1_sentence\"]=final_outputs\n"
     ]
    }
   ],
   "source": [
    "df=create_embeddings_1_sentence(df1[0:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_240001/347003246.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outputs.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputs_to_csv(df): \n",
    "    temp_output=[] \n",
    "\n",
    "    for a in range(df[\"output_1_sentence\"].shape[0]): \n",
    "       \n",
    "        article=df[\"output_1_sentence\"][a]\n",
    "        individual_output=[]\n",
    "\n",
    "        for b in range(len(article)): \n",
    "            \n",
    "            individual_token.append(article[b].tolist()) \n",
    "            \n",
    "        temp_output.append(individual_output)\n",
    "    \n",
    "\n",
    "    df[\"output_1_sentence\"]=temp_output\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def outputs_from_csv(df): \n",
    "    temp_output=[] \n",
    "\n",
    "    for a in range(df[\"output_1_sentence\"].shape[0]): \n",
    "       \n",
    "        article=ast.literal_eval(df[\"output_1_sentence\"][a])\n",
    "        individual_output=[]\n",
    "\n",
    "        for b in range(len(article)): \n",
    "            \n",
    "            individual_token.append(torch.tensor((article[b])))\n",
    "            \n",
    "        temp_output.append(individual_output)\n",
    "    \n",
    "\n",
    "    df[\"output_1_sentence\"]=temp_output\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have the outputs,which are the values after each of the 12 hidden layers and the output we need to to extract the word/sentence embeddings\n",
    "#Lets start with sentence embeddings\n",
    "#inspired by https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/ though not exactely the same.\n",
    "\n",
    "def bert_output_sentence_converter(output): \n",
    "    #output[2] is the hidden layer's final values + output of the model\n",
    "    #size= [13, 1, 52, 768]\n",
    "    hidden_layers_output=torch.stack(output[2], dim=0) \n",
    "   \n",
    "    # I borrowed my Extraction decision from the link below, to take the last four hidden layers and get the sum of them.\n",
    "    # check out http://jalammar.github.io/illustrated-bert/ for an intresting study on which hidden model we should extract from\n",
    "    final_four_layer_word_embeddings=hidden_layers_output[-4:][0] \n",
    "\n",
    "    sum_of_four_layers=torch.sum(torch.stack([final_four_layer_word_embeddings]), dim=0)\n",
    "    individual_word_embeddings = torch.squeeze(sum_of_four_layers, dim=0)\n",
    "\n",
    "    #to get a \"sentence embedding\" out of the word embeddings, I will simply get the average of all the word embeddings for each sentence\n",
    "    sentence_embeddings=torch.mean(individual_word_embeddings , dim=0)\n",
    "    \n",
    "    return sentence_embeddings\n",
    "\n",
    "\n",
    "bert_sentence_embeddings=[]\n",
    "for a in range(df.shape[0]): \n",
    "    article_output=df[\"output_1_sentence\"][a]\n",
    "    sentence_embeddings=[]\n",
    "\n",
    "    for b in range(len(article_output)):\n",
    "        sentence_output=article_output[b]\n",
    "        #takes sentence and calculated sentence embeddings\n",
    "        embedding=bert_output_sentence_converter(sentence_output)\n",
    "        sentence_embeddings.append(embedding)\n",
    "\n",
    "    bert_sentence_embeddings.append(sentence_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print(len(bert_sentence_embeddings)) \n",
    "print(bert_sentence_embeddings[0][1].size())\n",
    "#size of bert size embeddings (#number of article numbers, #number of sentences per ,# word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwf=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Embeddings will be similar to Sentence embeddings\n",
    "\n",
    "#This is inspired by https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/ though how the word embedding itself is created is different\n",
    "def bert_output_word_converter(output): \n",
    "    #output[2] is the hidden layer's final values + output of the model\n",
    "    #size= [13, 1, 52, 768]\n",
    "    hidden_layers_output=torch.stack(output[2], dim=0) \n",
    "   \n",
    "    #normally, bert will have a batches (the [1] dimension), but since we have one, lets squeeze it out\n",
    "      #size= [13, 52, 768]\n",
    "    hidden_layers_output = torch.squeeze(hidden_layers_output, dim=1)\n",
    "    \n",
    "    # we now have a tensor with the right dimensions, but it would be easier if we could go word by word rather than layer by layer \n",
    "    #size[52,12,768]\n",
    "    hidden_layers_output = hidden_layers_output.permute(1,0,2)\n",
    "\n",
    "    \n",
    "    # I borrowed my Extraction decision from the link below, to take the last four hidden layers and get the sum of them \n",
    "    # check out http://jalammar.github.io/illustrated-bert/ for an intresting study on which hidden model we should extract from\n",
    "   \n",
    "\n",
    "    word_embeddings=[]\n",
    "    for word in hidden_layers_output:\n",
    "        \n",
    "        sum_of_hidden=torch.sum(torch.stack([word[-4],word[-3],word[-2],word[-1]]), dim=0)\n",
    "        word_embeddings.append(sum_of_hidden)\n",
    "\n",
    "    return word_embeddings\n",
    "\n",
    "\n",
    "bert_word_embeddings=[]\n",
    "for a in range(df.shape[0]): \n",
    "    article_output=df[\"output_1_sentence\"][a]\n",
    "    word_embeddings=[]\n",
    "\n",
    "    for b in range(len(article_output)):\n",
    "        sentence_output=article_output[b]\n",
    "        #takes a sentence and converts it into its word embeddings\n",
    "        embedding=bert_output_word_converter(sentence_output)\n",
    "        word_embeddings.append(embedding)\n",
    "        \n",
    "\n",
    "    bert_word_embeddings.append(word_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now that we have a tf_idf, matrix, we notice that there is a problem with sizing? For the sake of this project, for the tf_idf, we will \n",
    "# we will pool tf_idf function with a linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "#Transformer While we do have already established \"Groupings\"from the 20 Newsgroup such as on Cars or certain Sports, with the massive amount of data, \n",
    "# I want to look at if Sentemce Embeddings pulled from bert works significantly better than lets say a simple TF-IDF Vector as a representation of the data in grouping these articles without a \n",
    "#Label\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,input_length=768,lstm_hidden_size=768,sequence_length=1,num_of_classes=20):\n",
    "        super().__init__()\n",
    "        ##YOUR CODE HERE##\n",
    "        \n",
    "        \n",
    "        self.input_length=input_length \n",
    "        self.lstm_hidden_size=lstm_hidden_size \n",
    "        self.sequence_length=sequence_length\n",
    "        self.num_of_classes=num_of_classes\n",
    "     \n",
    "\n",
    "        #Step 1 RNN/lstm\n",
    "\n",
    "        self.rnn= torch.nn.RNN(input_size=768,hidden_size=128,num_layers=1)\n",
    "        \n",
    "        #Step two Relu layers \n",
    "        self.relu_layer_1=torch.nn.Linear(lstm_hidden_size,128)\n",
    "        self.relu_layer_2=torch.nn.Linear(128,64)\n",
    "        \n",
    "        #Step 3 linear layer\n",
    "        self.linear_layer_1=torch.nn.Linear(64,num_of_classes)\n",
    "\n",
    "        #Step 4 Softmax layers \n",
    "        self.soft_max=torch.nn.Softmax(dim=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        h0 = torch.randn(1,1,self.lstm_hidden_size).requires_grad_()\n",
    "        \n",
    "        # Initialize cell state\n",
    "        \n",
    "        #Step 1 RNN/LSTM \n",
    "        x,hn =self.rnn(x,h0)\n",
    "      \n",
    "        if self.sequence_length>1: \n",
    "            x=torch.sum(x,dim=0)\n",
    "        \n",
    "        #Step two Relu dense layers\n",
    "        \n",
    "        y=self.relu_layer_1(x)\n",
    "        y=torch.nn.functional.relu(y) \n",
    "        y=self.relu_layer_2(y) \n",
    "        y=torch.nn.functional.relu(y)\n",
    "        #Step 3 linear layers \n",
    "        y=self.linear_layer_1(y) \n",
    "\n",
    "        #Step 4 Softmax layer\n",
    "        predictions=self.soft_max(y)\n",
    "      \n",
    "              \n",
    "        return(predictions) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the idea of my loss function is that  there needs to be away to \"reward\" the model if it predicts \n",
    "# a similar category (i.e if the class related to atheism was mistaken for an article on christianity, there should be some difference compared to if it was predicted as a basketball article)\n",
    "\n",
    "def individual_loss_function(predictions,reality):\n",
    "    #religion\n",
    "    key=[[0,15,18],[1,2,3,4,5],[6],[7,8,9,10],[11,12,13,14],[16,17,18]]\n",
    "    \n",
    "\n",
    "\n",
    "    predictions=predictions.squeeze(dim=0)\n",
    "    predictions=predictions.squeeze(dim=0)\n",
    "    #for loss one, i am only considering two things. If it is in the right group or not (a binary classifcation)\n",
    " \n",
    "    #checks if it got in the \"ballpark\" categories\n",
    "    pos_prob=0\n",
    "    for group in range(len(key)): \n",
    "        \n",
    "        if reality in key[group]:\n",
    "            for a in range(len(key[group])):\n",
    "        \n",
    "                pos_prob+=predictions[a]\n",
    "\n",
    "    pos_prob=torch.tensor(pos_prob)         \n",
    "    loss1=-1*torch.log(pos_prob)\n",
    "    #general cross loss function\n",
    "    loss2=-1*torch.log(predictions[reality])\n",
    "    loss=loss1+loss2\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "def run_model_sentence(bert_sentence_embeddings,epoch=100):\n",
    "    \n",
    "    learning_rate=.05\n",
    "    epoch=epoch\n",
    "    \n",
    "    article_realities=twenty_news_train.target[0:len(bert_sentence_embeddings)]\n",
    "  \n",
    "    \n",
    "    sentence_model=Model(input_length=768,lstm_hidden_size=128)\n",
    "    optimizer = torch.optim.SGD(sentence_model.parameters(), lr=learning_rate) \n",
    "    final_predictions=[]\n",
    "    for epochs in range(epoch):\n",
    "        for a in range(len(bert_sentence_embeddings)): \n",
    "            \n",
    "            article=bert_sentence_embeddings[a]\n",
    "            article_reality=article_realities[a]\n",
    "            prediction_list=[] \n",
    "            for b in range(len(article)):\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                x=article[b]\n",
    "                x=x.unsqueeze(dim=0)\n",
    "                x=x.unsqueeze(dim=0)\n",
    "               \n",
    "                predictions=sentence_model(x)\n",
    "               \n",
    "                loss= individual_loss_function(predictions,article_reality)\n",
    "\n",
    "                loss.backward() \n",
    "                optimizer.step()\n",
    "                \n",
    "                if epochs==(epoch-1):\n",
    "                    prediction=predictions.squeeze(dim=0) \n",
    "                    prediction=prediction.squeeze(dim=0) \n",
    "                    prediction=torch.argmax(prediction)\n",
    "                    sent_prediction=predictions.argmax()\n",
    "                    prediction_list.append(sent_prediction.item())\n",
    "                  \n",
    "            \n",
    "            if epochs==(epoch-1):\n",
    "                article_prediction=max(set(prediction_list), key=prediction_list.count)\n",
    "                final_predictions.append(article_prediction)\n",
    "                \n",
    "        if epochs%20==0: \n",
    "            print(loss)\n",
    "       \n",
    "    \n",
    "    return(sentence_model,final_predictions)\n",
    "        \n",
    "        \n",
    "        \n",
    "def run_model_word(bert_word_embeddings,epoch=100): \n",
    "\n",
    "    \n",
    "    learning_rate=.05\n",
    "    epoch=100\n",
    "    \n",
    "    article_realities=twenty_news_train.target[0:len(bert_word_embeddings)]\n",
    "    word_model=Model(input_length=768,lstm_hidden_size=128)\n",
    "    optimizer = torch.optim.SGD(word_model.parameters(), lr=learning_rate) \n",
    "    final_predictions=[]\n",
    "    for epochs in range(epoch):\n",
    "        \n",
    "        for a in range(len(bert_word_embeddings)): \n",
    "            \n",
    "            article=bert_word_embeddings[a]\n",
    "            article_reality=article_realities[a]\n",
    "            prediction_list=[] \n",
    "            for b in range(len(article)):\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                #sentence is a list of tensors (52,768)\n",
    "                sentence=article[b]\n",
    "                #lets convert to a tensor of lists\n",
    "                #(52,768)\n",
    "                sentence=torch.stack(sentence[:])\n",
    "        \n",
    "\n",
    "                #x is a (1,52,768)\n",
    "                x=sentence.unsqueeze(dim=0)\n",
    "                #x= (52,1,769)\n",
    "                x=x.permute(1,0,2)\n",
    "             \n",
    "               \n",
    "                predictions=word_model(x)\n",
    "               \n",
    "        \n",
    "                loss= individual_loss_function(predictions,article_reality) \n",
    "                loss=loss[0].sum()/20\n",
    "    \n",
    "                loss.backward() \n",
    "                optimizer.step()\n",
    "                \n",
    "                if epochs==(epoch-1):\n",
    "                    prediction=predictions.squeeze(dim=0) \n",
    "                    prediction=prediction.squeeze(dim=0) \n",
    "                    prediction=torch.argmax(prediction)\n",
    "                    word_prediction=predictions.argmax()\n",
    "                    prediction_list.append(word_prediction.item())\n",
    "            if epochs==(epoch-1):    \n",
    "                article_prediction=max(set(prediction_list), key=prediction_list.count)\n",
    "                final_predictions.append(article_prediction) \n",
    "        \n",
    "        if epochs%20==0: \n",
    "            print(loss) \n",
    "            \n",
    "            \n",
    "                \n",
    "    \n",
    "    \n",
    "    return(word_model,final_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshu\\AppData\\Local\\Temp\\ipykernel_7120\\645437719.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_prob=torch.tensor(pos_prob)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Joshu\\Downloads\\Final Project Lign 167\\Untitled-1.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Joshu/Downloads/Final%20Project%20Lign%20167/Untitled-1.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sentence_model,prediction_sentence\u001b[39m=\u001b[39mrun_model_sentence(bert_sentence_embeddings[\u001b[39m0\u001b[39;49m:\u001b[39m180\u001b[39;49m],epoch\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Joshu\\Downloads\\Final Project Lign 167\\Untitled-1.ipynb Cell 24\u001b[0m in \u001b[0;36mrun_model_sentence\u001b[1;34m(bert_sentence_embeddings, epoch)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Joshu/Downloads/Final%20Project%20Lign%20167/Untitled-1.ipynb#X32sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m predictions\u001b[39m=\u001b[39msentence_model(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Joshu/Downloads/Final%20Project%20Lign%20167/Untitled-1.ipynb#X32sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m loss\u001b[39m=\u001b[39m individual_loss_function(predictions,article_reality)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Joshu/Downloads/Final%20Project%20Lign%20167/Untitled-1.ipynb#X32sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward() \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Joshu/Downloads/Final%20Project%20Lign%20167/Untitled-1.ipynb#X32sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Joshu/Downloads/Final%20Project%20Lign%20167/Untitled-1.ipynb#X32sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mif\u001b[39;00m epochs\u001b[39m==\u001b[39m(epoch\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Joshu\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\Joshu\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentence_model,prediction_sentence=run_model_sentence(bert_sentence_embeddings[0:180],epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshu\\AppData\\Local\\Temp\\ipykernel_7120\\1166918816.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_prob=torch.tensor(pos_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6055, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "word_model,prediction_word=run_model_word(bert_word_embeddings[0:180],epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "#Now how do we determine success? lets look at some insights\n",
    "\n",
    "def precise_confusion_matrix(actual,prediction_orig,length):\n",
    "    \n",
    "    list_of_predictions=[]\n",
    "    for a in range(length):\n",
    "        prediction=prediction_orig[a]\n",
    "        list_of_predictions.append(prediction) \n",
    "       \n",
    "    #grabbed from https://stackoverflow.com/questions/38877301/how-to-calculate-accuracy-based-on-two-lists-python\n",
    "    list_of_predictions=np.array(list_of_predictions)\n",
    "    actual=np.array(actual)\n",
    "    correct = (list_of_predictions == actual)\n",
    "    accuracy = float(correct.sum()/length)\n",
    "    print(accuracy)\n",
    "    \n",
    "    \n",
    "    \n",
    "def general_confusion_matrix(actual,prediction_orig,length): \n",
    "    key=[[0,15,18],[1,2,3,4,5],[6],[7,8,9,10],[11,12,13,14],[16,17,18]]\n",
    "    \n",
    "    list_of_predictions=[]\n",
    "    for a in range(length):\n",
    "        prediction=prediction_orig[a]\n",
    "        list_of_predictions.append(prediction)\n",
    "    \n",
    "    for b in range(length): \n",
    "        for group in range(len(key)): \n",
    "            if list_of_predictions[b] in key[group]: \n",
    "                list_of_predictions[b]=group\n",
    "            if actual[b] in key[group]: \n",
    "                actual[b]=group      \n",
    "   \n",
    "\n",
    "    list_of_predictions=np.array(list_of_predictions)\n",
    "    actual=np.array(actual)\n",
    "    correct = (list_of_predictions == actual)  \n",
    "    accuracy=float(correct.sum()/length)\n",
    "    print(accuracy)\n",
    "\n",
    "    \n",
    "     \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precise_confusion_matrix(twenty_news_train.target[0:180],prediction_word,180)\n",
    "general_confusion_matrix(twenty_news_train.target[0:180],prediction_word,180)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4670fc71c1cae8bb0a1a459834888818b1db862995a203c305d8455da6d800ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
